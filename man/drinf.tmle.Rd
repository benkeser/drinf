% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/drinf.tmle.R
\name{drinf.tmle}
\alias{drinf.tmle}
\title{drinf.tmle}
\usage{
drinf.tmle(L0, L1, L2, A0, A1, abar = c(1, 1), stratify = TRUE,
  SL.Q = NULL, SL.g = NULL, SL.Qr = NULL, SL.gr = NULL, glm.Q = NULL,
  glm.g = NULL, guard = c("Q", "g"), universal = FALSE,
  universalStepSize = 1e-04, printFreq = 50, flucOrd = c("targetQ2",
  "targetQ1", "targetg1", "targetg0"), return.models = FALSE, maxIter = 20,
  tolIF = 1/(length(L2)), tolg = 1e-08, tolQ = 1e-08, verbose = TRUE,
  SL.Q.options = list(family = gaussian()), SL.g.options = list(family =
  binomial()), glm.Q.options = list(family = gaussian()),
  return.ltmle = TRUE, return.naive = TRUE, ...)
}
\arguments{
\item{L0}{A \code{data.frame} featuring covariates measured at baseline.}

\item{L1}{A \code{data.frame} featuring time-varying covariates measured at 
the first timepoint.}

\item{L2}{A \code{vector} outcome of interest}

\item{A0}{A \code{vector} treatment delivered at baseline.}

\item{A1}{A \code{vector} treatment deliver after \code{L1} is measured.}

\item{abar}{A \code{vector} of length 2 indicating the treatment assignment 
that is of interest.}

\item{stratify}{A \code{boolean} indicating whether to pool across treatment
nodes or to estimate outcome regression separately in each category. Should be 
kept \code{TRUE} until I have more time to think about how to pool across 
treatment arms?}

\item{SL.Q}{A \code{vector} or \code{list} specifying the SuperLearner library
to be used to estimate the outcome regressions at each time point. See \code{SuperLearner}
package for details.}

\item{SL.g}{A \code{vector} or \code{list} specifying the SuperLearner library
to be used to estimate the conditional probability of treatment at each time point.  See \code{SuperLearner}
package for details.}

\item{SL.Qr}{A \code{vector} or \code{list} specifying the SuperLearner library
to be used to estimate the reduced-dimension regression to protect against misspecification of the
outcome regressions.  See \code{SuperLearner} package for details.}

\item{SL.gr}{A \code{vector} or \code{list} specifying the SuperLearner library
to be used to estimate the reduced-dimension regression to protect against misspecification of the
conditional treatment probabilities. See \code{SuperLearner} package for details.}

\item{glm.Q}{A \code{character} specifying the right-hand side of the \code{glm} 
formula used to estimate the outcome regressions at each time point. Only used if \code{SL.Q = NULL}.}

\item{glm.g}{A \code{character} specifying the right-hand side of the \code{glm} 
formula used to estimate the conditional probability of treatment at each time point. 
Only used if \code{SL.g = NULL}.}

\item{guard}{A \code{vector} of \code{characters}, either \code{"Q"}, \code{"g"}, both, or neither (\code{NULL}).
Indicates whether to guard against misspecification of outcome or treatment regressions or both. Currently only works
with \code{c("Q","g")}.}

\item{universal}{A \code{boolean} indicating whether to perform TMLE step using locally least favorable
parametric submodels (if \code{FALSE}) or universally least favorable submodels (if \code{TRUE})}

\item{universalStepSize}{A \code{numeric} indicating the step size for the recursive calculation of 
universally least favorable submodel. Default is \code{0.005}.}

\item{return.models}{A \code{boolean} indicating whether the models for Q, g, Qr, and gr should be 
returned with the output.}

\item{maxIter}{A \code{numeric} indicating the maximum number of TMLE iterations before stopping.}

\item{tolIF}{A \code{numeric} stopping criteria for the TMLE updates based on the empirical average of the 
estimated influence curve.}

\item{tolg}{A \code{numeric} indicating the truncation level for conditional treatment probabilities.}

\item{tolQ}{A \code{numeric} indicating the truncation level for transformed outcome regressions.}

\item{verbose}{A \code{boolean} indicating whether messages should be printed to indicate progress.}

\item{SL.Q.options}{A \code{list} of additional arguments passed to \code{SuperLearner} for outcome
regression fits.}

\item{SL.g.options}{A \code{list} of additional arguments passed to \code{SuperLearner} for condtional treatment 
probability fits.}

\item{glm.Q.options}{A \code{list} of additional arguments passed to \code{glm} for outcome
regression fits.}

\item{return.ltmle}{A \code{boolean} indicating whether to compute the LTMLE estimate using a similar
iterative updating scheme.}

\item{return.naive}{A \code{boolean} indicating whether to return the naive plug-in estimate.}

\item{...}{Other arguments (not currently used)}
}
\value{
TO DO: Add return values
}
\description{
This function computes the time-varying covariate-adjusted mean of 
an outcome under a specified treatment assignment using targeted 
minimum loss-based estimation.
}
\examples{
TO DO : Add Examples
}

